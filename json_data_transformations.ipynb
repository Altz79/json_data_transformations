{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b54e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "\n",
    "#technical tools\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import ChainMap\n",
    "\n",
    "# ML libraries\n",
    "from nltk.metrics import edit_distance\n",
    "from sklearn.metrics import jaccard_score\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68258cac",
   "metadata": {},
   "source": [
    "<font size=\"3\">Constructing unified dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use your path \n",
    "path = r'C:\\Users\\altz7\\Downloads\\physics_conference'\n",
    "all_files = glob.glob(path + \"\\*.json\")\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_json(filename)\n",
    "    data_list.append(df)\n",
    "\n",
    "main_data = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ef059",
   "metadata": {},
   "source": [
    "<font size=\"3\">Unpack data from nested dictionary values </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google_scholar\n",
    "\n",
    "google_scholar = main_data[\"google_scholar\"].progress_apply(pd.Series)\n",
    "\n",
    "google_scholar_list = []\n",
    "\n",
    "for col in google_scholar.columns:\n",
    "    \"\"\"\n",
    "    unpack all columns for each search result column\n",
    "    columns are named like integers 0, 1, 2. Total number depends on how many names are given. \n",
    "    If in some row 5 names are provided than total number of columns will be also 5 - to create space for placing all data\n",
    "    \n",
    "    Each \"google_scholar_element\" will represent all data given for each name inside this search result    \n",
    "    \"\"\"\n",
    "    google_scholar_element = google_scholar[col].progress_apply(pd.Series) #unpack all columns for each search result column\n",
    "    \n",
    "    #remove columns that named as \"0\", no information in it\n",
    "    only_str_columns = [c for c in google_scholar_element.columns if isinstance(c, (str))]\n",
    "    google_scholar_element = google_scholar_element[google_scholar_element.columns.intersection(only_str_columns)]\n",
    "    \n",
    "    google_scholar_element = google_scholar_element.add_suffix('_' + str(col)) #rename column for each set of columns for each provided name\n",
    "    google_scholar_list.append(google_scholar_element)\n",
    "    \n",
    "google_scholar = pd.concat(google_scholar_list, axis=1) #google_scholar dataframe with all data\n",
    "del google_scholar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResearchGate\n",
    "\n",
    "main_data[\"researchgate_dict\"] = main_data[\"researchgate\"].apply(lambda row: dict(ChainMap(*row)))\n",
    "\n",
    "researchgate = main_data[\"researchgate_dict\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c481ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinkedIn\n",
    "\n",
    "linkedin = main_data[\"linkedin\"].progress_apply(pd.Series)\n",
    "\n",
    "linkedin_list = []\n",
    "\n",
    "def extract_linkedin_affiliation(row):\n",
    "    list_value = row[\"LinkedIn_Experience\"]\n",
    "    if len(list_value) > 0:\n",
    "        dict_value = list_value[0]\n",
    "        return dict_value['company_name']\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "def extract_linkedin_interests(row):\n",
    "    list_of_interests = []\n",
    "    list_value = row[\"LinkedIn_Skills\"]\n",
    "    if len(list_value) > 0:\n",
    "        for element in list_value:\n",
    "            #extract data for each of available \"name_of_skill\" from dictionary: [{'name_of_skill': 'Research'}, {'name_of_skill': 'Experimental Physics'}]\n",
    "            list_of_interests.append(element['name_of_skill'])\n",
    "        return \", \".join(list_of_interests)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "for col in linkedin.columns:\n",
    "    #unpack all columns for each search result column\n",
    "    linkedin_element = linkedin[col].progress_apply(pd.Series)\n",
    "    \n",
    "    #remove columns that named as \"0\", no information in it\n",
    "    only_str_columns = [c for c in linkedin_element.columns if isinstance(c, (str))]\n",
    "    linkedin_element = linkedin_element[linkedin_element.columns.intersection(only_str_columns)]\n",
    "    \n",
    "    #replace NaN values for empty list\n",
    "    linkedin_element.loc[linkedin_element['LinkedIn_Experience'].isnull(),['LinkedIn_Experience']] = linkedin_element.loc[linkedin_element['LinkedIn_Experience'].isnull(), \\\n",
    "                                                                                                                          'LinkedIn_Experience'].apply(lambda x: [])\n",
    "    \n",
    "    linkedin_element.loc[linkedin_element['LinkedIn_Skills'].isnull(),['LinkedIn_Skills']] = linkedin_element.loc[linkedin_element['LinkedIn_Skills'].isnull(), \\\n",
    "                                                                                                                          'LinkedIn_Skills'].apply(lambda x: [])\n",
    "  \n",
    "    #get affiliation from \"LinkedIn_Experience\" column\n",
    "    linkedin_element[\"LinkedIn_affiliation\"] = linkedin_element.apply(lambda row: extract_linkedin_affiliation(row), axis=1)\n",
    "    \n",
    "    # Extract LinkedIn_interests -> will use column \"LinkedIn_Skills\", not \"LinkedIn_Interests\" cause it doesn't contain relevant data\n",
    "    #get interests from \"LinkedIn_Skills\" column\n",
    "    linkedin_element[\"LinkedIn_interests\"] = linkedin_element.apply(lambda row: extract_linkedin_interests(row), axis=1)\n",
    "   \n",
    "    #rename column for each set of columns for each provided name\n",
    "    linkedin_element = linkedin_element.add_suffix('_' + str(col)) \n",
    "    linkedin_list.append(linkedin_element)\n",
    "\n",
    "#google_scholar dataframe with all data\n",
    "linkedin = pd.concat(linkedin_list, axis=1)\n",
    "del linkedin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orcid\n",
    "\n",
    "main_data[\"orcid_dict\"] = main_data[\"orcid\"].apply(lambda row: dict(ChainMap(*row)))\n",
    "\n",
    "orcid = main_data[\"orcid_dict\"].apply(pd.Series)\n",
    "\n",
    "# Extract Orcid_affiliation\n",
    "orcid.loc[orcid['Orcid_Employment'].isnull(),['Orcid_Employment']] = orcid.loc[orcid['Orcid_Employment'].isnull(), \\\n",
    "                                                                               'Orcid_Employment'].apply(lambda x: [])\n",
    "def extract_orcid_affiliation(row):\n",
    "    list_value = row[\"Orcid_Employment\"]\n",
    "    if len(list_value) > 0:\n",
    "        dict_value = list_value[0]\n",
    "        return dict_value['affiliation_name']\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "orcid[\"Orcid_affiliation\"] = orcid.apply(lambda row: extract_orcid_affiliation(row), axis=1)\n",
    "\n",
    "# Transform Orcid_interests\n",
    "orcid.loc[orcid['Orcid_Keywords'].isnull(),['Orcid_Keywords']] = orcid.loc[orcid['Orcid_Keywords'].isnull(), \\\n",
    "                                                                               'Orcid_Keywords'].apply(lambda x: [])\n",
    "\n",
    "def extract_orcid_interests(row):\n",
    "    list_value = row[\"Orcid_Keywords\"]\n",
    "    if len(list_value) > 0:\n",
    "        return \", \".join(list_value)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "orcid[\"Orcid_interests\"] = orcid.apply(lambda row: extract_orcid_interests(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d01518",
   "metadata": {},
   "source": [
    "<font size=\"3\">Combine search results data with main data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedecd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.concat([main_data, researchgate, google_scholar, linkedin, orcid], axis=1)\n",
    "\n",
    "#create \"full_name\" column for original data\n",
    "main_data.insert(0, 'full_name', main_data[\"first_name\"] + \" \" + main_data[\"last_name\"])\n",
    "main_data.drop(columns=['first_name', 'last_name'])\n",
    "\n",
    "#fill NaN values with empty string\n",
    "main_data.fillna('', inplace = True)\n",
    "\n",
    "#free memory space\n",
    "del researchgate, google_scholar, linkedin, orcid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1db4f6",
   "metadata": {},
   "source": [
    "<font size=\"3\">Preprocessing the names columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e742447",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_scholar_name_columns = [c for c in main_data.columns if \"GoogleScholar_Name\" in c]\n",
    "\n",
    "linkedin_name_columns = [c for c in main_data.columns if \"LinkedIn_Full_Name\" in c]\n",
    "\n",
    "name_columns = [\"full_name\", \"ResearchGate_Full_Name\", \"Orcid_Full_Name\"] \\\n",
    "                + google_scholar_name_columns \\\n",
    "                + linkedin_name_columns\n",
    "\n",
    "def remove_chinese_characters(name):\n",
    "    chinese_characters = re.sub(\"[^\\u4E00-\\u9FA5]\", \"\", str(name))\n",
    "    name = name.replace(chinese_characters, \"\")\n",
    "    return name\n",
    "\n",
    "def preprocess_names(name):\n",
    "    name = name.str.title()\n",
    "    name = name.str.replace(\"(\", \"\").str.replace(\")\", \"\").str.replace(\"Dr. \", \"\").str.replace(\" PhD\", \"\") \\\n",
    "                .str.replace(\"Ph.D.\", \"\").str.replace(\"Ph. D.\", \"\").str.replace(\",\", \"\")\n",
    "    name = name.str.strip()\n",
    "    return name\n",
    "\n",
    "#apply function to string objects\n",
    "for col in name_columns:\n",
    "    main_data[col] = main_data[col].apply(remove_chinese_characters)\n",
    "\n",
    "#apply function to series (columns)\n",
    "main_data[name_columns] = main_data[name_columns].apply(preprocess_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3eedce",
   "metadata": {},
   "source": [
    "<font size=\"3\">Scoring system</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzz_score_for_mult_columns(required_columns: list, new_column_name: str):\n",
    "    \"\"\"\n",
    "    Creates score for set of LinkedIn and GoogleScholar columns\n",
    "    \n",
    "    :param1 required_columns: list of columns to apply function \n",
    "    :param2 new_column_name: general column name, like \"score_name_origin_linkedin\"\n",
    "    \n",
    "    \"\"\"\n",
    "    for col in required_columns:\n",
    "        suffix_linkedin = col[-2:]\n",
    "        main_data[new_column_name + suffix_linkedin] = main_data[[\"full_name\", col]].apply(lambda x: fuzz.partial_ratio(*x), axis=1)\n",
    "        \n",
    "def jaccard_score_for_mult_columns(required_columns: list, new_column_name: str, original_data_column: str):\n",
    "    \"\"\"\n",
    "    Creates score for set of LinkedIn and GoogleScholar columns\n",
    "    \n",
    "    :param1 required_columns: list of columns to apply function \n",
    "    :param2 new_column_name: general column name, like \"score_name_origin_linkedin\"\n",
    "    :param3 original_data_column: column name to compare with from original data\n",
    "    \n",
    "    \"\"\"\n",
    "    for col in required_columns:\n",
    "        suffix_linkedin = col[-2:]\n",
    "        main_data[new_column_name + suffix_linkedin] = main_data.apply(lambda x: improved_jaccard_similarity(x[original_data_column], x[col]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name similarity between original data and each of 4 search results\n",
    "\n",
    "main_data[\"score_name_origin_researchgate\"] = main_data[[\"full_name\", \"ResearchGate_Full_Name\"]].apply(lambda x: fuzz.partial_ratio(*x), axis=1)\n",
    "\n",
    "main_data[\"score_name_origin_orcid\"] = main_data[[\"full_name\", \"Orcid_Full_Name\"]].apply(lambda x: fuzz.partial_ratio(*x), axis=1)\n",
    "\n",
    "fuzz_score_for_mult_columns(linkedin_name_columns, \"score_name_origin_linkedin\")\n",
    "\n",
    "fuzz_score_for_mult_columns(google_scholar_name_columns, \"score_name_origin_googlescholar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939da575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiliation similarity between original data and each of 4 search results\n",
    "\n",
    "\"\"\"\n",
    "Jaccard similarity takes into account only the set of unique words for each text document. \n",
    "This makes it the likely candidate for assessing the similarity of documents when repetition is not an issue. \n",
    "A prime example of such an application is comparing product descriptions. \n",
    "For instance, if a term like “HD” or “thermal efficiency” is used multiple times in one description and just once in another, \n",
    "the Euclidean distance and cosine similarity would drop. On the other hand, \n",
    "if the total number of unique words stays the same, the Jaccard similarity will remain unchanged. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def jaccard_similarity(x, y):\n",
    "    \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "    if len(x) != 0 and len(y) != 0:\n",
    "        intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "        union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "        return intersection_cardinality / float(union_cardinality)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def improved_jaccard_similarity(x, y):\n",
    "    if len(x) != 0 and len(y) != 0:\n",
    "        sentences = [x, y]\n",
    "        sentences = [sent.lower().split(\" \") for sent in sentences]\n",
    "        return jaccard_similarity(sentences[0], sentences[1])\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# get list of affiliation columns for LinkedIn and GScholar\n",
    "\n",
    "google_scholar_affiliation_columns = [c for c in main_data.columns if \"GoogleScholar_Organization\" in c]\n",
    "\n",
    "linkedin_affiliation_columns = [c for c in main_data.columns if \"LinkedIn_affiliation\" in c]\n",
    "\n",
    "#create scrore columns for affiliation\n",
    "\n",
    "jaccard_score_for_mult_columns(linkedin_affiliation_columns, \"score_affiliation_origin_linkedin\", 'affiliation')\n",
    "\n",
    "jaccard_score_for_mult_columns(google_scholar_affiliation_columns, 'score_affiliation_origin_googlescholar', 'affiliation')\n",
    "\n",
    "main_data['score_affiliation_origin_researchgate'] = main_data.apply(lambda x: improved_jaccard_similarity(x['affiliation'], x['ResearchGate_Affiliation']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_origin_orcid'] = main_data.apply(lambda x: improved_jaccard_similarity(x['affiliation'], x['Orcid_affiliation']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiliation similarity between 4 search results\n",
    "\n",
    "# For LinkedIn and GScholar done between first name given\n",
    "\n",
    "main_data['score_affiliation_linkedin_googlescholar'] = main_data.apply(lambda x: improved_jaccard_similarity(x['LinkedIn_affiliation_0'], x['GoogleScholar_Organization_0']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_linkedin_researchgate'] = main_data.apply(lambda x: improved_jaccard_similarity(x['LinkedIn_affiliation_0'], x['ResearchGate_Affiliation']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_linkedin_orcid'] = main_data.apply(lambda x: improved_jaccard_similarity(x['LinkedIn_affiliation_0'], x['Orcid_affiliation']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_researchgate_orcid'] = main_data.apply(lambda x: improved_jaccard_similarity(x['ResearchGate_Affiliation'], x['Orcid_affiliation']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_researchgate_googlescholar'] = main_data.apply(lambda x: improved_jaccard_similarity(x['ResearchGate_Affiliation'], x['GoogleScholar_Organization_0']), axis=1)\n",
    "\n",
    "main_data['score_affiliation_orcid_googlescholar'] = main_data.apply(lambda x: improved_jaccard_similarity(x['Orcid_affiliation'], x['GoogleScholar_Organization_0']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interests similarity between original data and each of 4 search results\n",
    "\n",
    "# get list of interests columns for LinkedIn and GScholar\n",
    "\n",
    "google_scholar_interest_columns = [c for c in main_data.columns if \"GoogleScholar_Interests\" in c]\n",
    "\n",
    "linkedin_interests_columns = [c for c in main_data.columns if \"LinkedIn_interests\" in c]\n",
    "\n",
    "#create scrore columns for affiliation\n",
    "\n",
    "jaccard_score_for_mult_columns(linkedin_interests_columns, 'score_interests_origin_linkedin', 'research_topics')\n",
    "\n",
    "jaccard_score_for_mult_columns(google_scholar_interest_columns, 'score_interests_origin_googlescholar', 'research_topics')\n",
    "\n",
    "main_data['score_interests_origin_researchgate'] = main_data.apply(lambda x: improved_jaccard_similarity(x['research_topics'], x['ResearchGate_Skills_and_Expertise']), axis=1)\n",
    "\n",
    "main_data['score_interests_origin_orcid'] = main_data.apply(lambda x: improved_jaccard_similarity(x['research_topics'], x['Orcid_interests']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final score for each of 4 search results\n",
    "\n",
    "\"\"\"\n",
    "WEIGHTING MATCHES: .70 FOR NAMES, .20 FOR AFFILIATION AND .10 FOR INTERESTS.\n",
    "\n",
    "\"\"\"\n",
    "for i in range(len(linkedin_name_columns)):\n",
    "    main_data['score_final_linkedin_{}'.format(i)] = (main_data[\"score_name_origin_linkedin_{}\".format(i)] * 0.7) \\\n",
    "                                                         + (main_data['score_affiliation_origin_linkedin_{}'.format(i)] * 0.2) \\\n",
    "                                                         + (main_data['score_interests_origin_linkedin_{}'.format(i)] * 0.1)\n",
    "    \n",
    "for i in range(len(google_scholar_name_columns)):\n",
    "    main_data['score_final_googlescholar_{}'.format(i)] = (main_data[\"score_name_origin_googlescholar_{}\".format(i)] * 0.7) \\\n",
    "                                                          + (main_data['score_affiliation_origin_googlescholar_{}'.format(i)] * 0.2) \\\n",
    "                                                          + (main_data['score_interests_origin_googlescholar_{}'.format(i)] * 0.1)\n",
    "    \n",
    "main_data['score_final_researchgate'] = (main_data[\"score_name_origin_researchgate\"] * 0.7) \\\n",
    "                                                          + (main_data['score_affiliation_origin_researchgate'] * 0.2) \\\n",
    "                                                          + (main_data['score_interests_origin_researchgate'] * 0.1)\n",
    "\n",
    "main_data['score_final_orcid'] = (main_data[\"score_name_origin_orcid\"] * 0.7) \\\n",
    "                                                          + (main_data['score_affiliation_origin_orcid'] * 0.2) \\\n",
    "                                                          + (main_data['score_interests_origin_orcid'] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5335aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best final score from all LinkedIn and Google_Scholar final scores \n",
    "\n",
    "# get best score result from all available\n",
    "\n",
    "all_score_linkedin = [c for c in main_data.columns if \"score_final_linkedin\" in c]\n",
    "\n",
    "all_score_googlescholar = [c for c in main_data.columns if \"score_final_googlescholar\" in c]\n",
    "\n",
    "all_score = all_score_linkedin + all_score_googlescholar + ['score_final_researchgate', 'score_final_orcid']\n",
    "\n",
    "\n",
    "main_data['best_linkedin'] = main_data[all_score_linkedin].idxmax(axis=1)\n",
    "\n",
    "main_data['best_googlescholar'] = main_data[all_score_googlescholar].idxmax(axis=1)\n",
    "\n",
    "main_data['best_score_of_all'] = main_data[all_score].idxmax(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
